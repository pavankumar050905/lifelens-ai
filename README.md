ðŸ‘‹ Hi, this is LifeLens AI â€” a fully multimodal assistant powered by Google Gemini.

Let me show you how it helps in real-life situations.

---

** Damage Photo Analysis**
Iâ€™ll start by uploading a photo of a broken device.
LifeLens automatically detects the damage, identifies the type of crack, and tells me whether it can be repaired.

It even gives step-by-step guidance and speaks out loud using Gemini audio mode.

---

 **2. Food Photo â†’ Calories + Nutrition**
Now letâ€™s analyze a food photo.
LifeLens identifies the food items automatically from the picture.

It estimates calories, nutrition values, and even gives personalized dietary suggestions.

---

 **3. BMI + Health Suggestions**
If I provide height and weight, LifeLens calculates BMI and determines my health category.

It then tailors recommendations based on both BMI and the food I uploaded.

---

 **4. Voice Input + Spoken Output**
I can ask LifeLens questions with my microphone, and the AI responds in natural audio using Geminiâ€™s speech output.

This makes the interaction seamless and accessible.

---

 **Conclusion**
LifeLens AI brings together vision, audio, nutrition, health, and repair assistance â€” all in a single experience powered by Google Gemini.

Thank you!

<div align="center">
<img width="1200" height="475" alt="GHBanner" src="https://github.com/user-attachments/assets/0aa67016-6eaf-458a-adb2-6e31a0763ed6" />
</div>

# Run and deploy your AI Studio app

This contains everything you need to run your app locally.

View your app in AI Studio: https://ai.studio/apps/drive/1qPPe7v4EN0jRXLuHvoW7bdl_59aZgAJs

## Run Locally

**Prerequisites:**  Node.js


1. Install dependencies:
   `npm install`
2. Set the `GEMINI_API_KEY` in [.env.local](.env.local) to your Gemini API key
3. Run the app:
   `npm run dev`
